{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faab79af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ebf3f9",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "These changes are implemented in the new architecture: GNNRecommenderwithSkipConnections. To summarise, there are 3 changes from the BaseGNNRecomender:\n",
    "\n",
    "1. Added skip connections\n",
    "2. Added batch norm layers\n",
    "3. Simplified MLP predictor to single feedforward layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5dbf6d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6962fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils.setup_nodes import create_edge_lists\n",
    "from utils.graph_helpers import train_model, plot_train_val_loss, final_evaluation, make_df\n",
    "from utils.graph_model import GNNSAGERecommenderwithSkipConnections\n",
    "from utils.general import seed_everything\n",
    "from utils.predictions import recommend_products, pretty_print_recomendations, get_top_k_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ec0cbf",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036c6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "335eaf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_split = \"train_test_valid\"\n",
    "prod_embed_name = \"meta_features_512\"\n",
    "user_embed_name = \"user_reviews_features_512\"\n",
    "\n",
    "data_dir = \"data\"\n",
    "product_dir = \"full_data\"\n",
    "embedding_dir = \"embedding\"\n",
    "results_folder = \"complex_sage_gnn\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "product_cols = [\"parent_asin\", \"average_rating\", \"rating_number\"]\n",
    "user_cols = [\"user_id\", \"rating_mean\", \"rating_count\", \"helpful_vote_mean\", \"helpful_vote_gte_1\", \"verified_purchase_mean\", \"last_active_in_days_min\",\n",
    "            \"last_active_in_days_max\", \"word_count_mean\"]\n",
    "edge_cols = [\"user_id\", \"parent_asin\", \"rating\"]\n",
    "\n",
    "fill_users = \"zero\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ad15db",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e78d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = pd.read_parquet(f\"{data_dir}/{product_dir}/product_df.parquet\", columns = product_cols)\n",
    "train_user_df = pd.read_parquet(f\"{data_dir}/{user_split}_split/train_agg.parquet\", columns = user_cols)\n",
    "train_user_edges = pd.read_parquet(f\"{data_dir}/{user_split}_split/train.parquet\", columns = edge_cols)\n",
    "\n",
    "if user_split == \"train_test_valid\":\n",
    "    test_user_df = pd.read_parquet(f\"{data_dir}/{user_split}_split/valid_agg.parquet\", columns = user_cols)\n",
    "    test_user_edges = pd.read_parquet(f\"{data_dir}/{user_split}_split/valid.parquet\", columns = edge_cols)\n",
    "else:\n",
    "    test_user_df = pd.read_parquet(f\"{data_dir}/{user_split}_split/test_agg.parquet\", columns = user_cols)\n",
    "    test_user_edges = pd.read_parquet(f\"{data_dir}/{user_split}_split/test.parquet\", columns = edge_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dc6f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_embedding = torch.load(f\"{data_dir}/{embedding_dir}/product/{prod_embed_name}.pt\")\n",
    "train_user_embedding = torch.load(f\"{data_dir}/{embedding_dir}/{user_split}_split/train_{user_embed_name}.pt\")\n",
    "if user_split == \"train_test_valid\":\n",
    "    test_user_embedding = torch.load(f\"{data_dir}/{embedding_dir}/{user_split}_split/valid_{user_embed_name}.pt\")\n",
    "else:\n",
    "    test_user_embedding = torch.load(f\"{data_dir}/{embedding_dir}/{user_split}_split/test_{user_embed_name}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ba499",
   "metadata": {},
   "source": [
    "# Make nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51709e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the embedding \n",
    "train_user_df[\"embedding\"] = list(train_user_embedding.numpy())\n",
    "test_user_df[\"embedding\"] = list(test_user_embedding.numpy())\n",
    "\n",
    "# Concat user nodes \n",
    "additional_test_users = test_user_df[~test_user_df.user_id.isin(train_user_df.user_id)].copy()\n",
    "\n",
    "## these are users that need to be zero-ed out \n",
    "additional_test_users = test_user_df[~test_user_df.user_id.isin(train_user_df.user_id)].copy()\n",
    "additional_test_users[\"embedding\"] = list(torch.zeros((len(additional_test_users), test_user_embedding.shape[1])).numpy())\n",
    "if fill_users == \"zero\":\n",
    "    additional_test_users.iloc[:, 1:-1] = 0\n",
    "elif fill_users == \"mean\":\n",
    "    additional_test_users.iloc[:, 1:-1] = train_user_df.iloc[:, 1:].mean()\n",
    "\n",
    "# Make super user df\n",
    "user_df = pd.concat([train_user_df, additional_test_users])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "591e1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up id mapping\n",
    "offset = user_df.user_id.nunique()\n",
    "user_id_to_idx = {unique_id : idx for idx, unique_id in enumerate(user_df.user_id.unique())}\n",
    "prod_id_to_idx = {unique_id : offset + idx for idx, unique_id in enumerate(product_df.parent_asin.unique())}\n",
    "\n",
    "# Add to df\n",
    "product_df[\"prod_idx\"] = product_df.parent_asin.apply(lambda x: prod_id_to_idx[x])\n",
    "train_user_edges[\"user_idx\"] = train_user_edges.user_id.apply(lambda x: user_id_to_idx[x])\n",
    "test_user_edges[\"user_idx\"] = test_user_edges.user_id.apply(lambda x: user_id_to_idx[x])\n",
    "train_user_edges[\"prod_idx\"] = train_user_edges.parent_asin.apply(lambda x: prod_id_to_idx[x])\n",
    "test_user_edges[\"prod_idx\"] = test_user_edges.parent_asin.apply(lambda x: prod_id_to_idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2105813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat product nodes \n",
    "product_nodes = torch.cat([torch.tensor(product_df.drop([\"parent_asin\", \"prod_idx\"], axis = 1).to_numpy()), product_embedding], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "775f57ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat user nodes \n",
    "user_embed = torch.tensor(np.vstack(user_df[\"embedding\"].values))\n",
    "user_info = torch.tensor(user_df.drop([\"user_id\", \"embedding\"], axis = 1).to_numpy())\n",
    "user_nodes = torch.cat([user_info, user_embed], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ccf9384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create edge list\n",
    "train_edge_index, train_edge_weights = create_edge_lists(train_user_edges)\n",
    "test_edge_index, test_edge_weights = create_edge_lists(train_user_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9311e4",
   "metadata": {},
   "source": [
    "# Move to GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8118624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_nodes = product_nodes.type(torch.float).to(device)\n",
    "user_nodes = user_nodes.type(torch.float).to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "train_edge_weights = train_edge_weights.to(device)\n",
    "test_edge_index = test_edge_index.to(device)\n",
    "test_edge_weights = test_edge_weights.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d2ac3a",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6576d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model features (fixed)\n",
    "num_users = len(user_df)\n",
    "num_products = len(product_df)\n",
    "user_feature_dim = user_nodes.shape[1]\n",
    "product_feature_dim = product_nodes.shape[1]\n",
    "\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "945d2ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config ls \n",
    "\n",
    "config_ls = []\n",
    "\n",
    "embedding_dim_ls = [16, 32, 64, 128, 256]\n",
    "learning_rate_ls = [0.01, 1e-3, 5e-4, 1e-4]\n",
    "dropout_prob_ls = [0.1, 0.3, 0.5]\n",
    "\n",
    "for embedding_dim in embedding_dim_ls:\n",
    "    for learning_rate in learning_rate_ls:\n",
    "        for dropout_prob in dropout_prob_ls:\n",
    "            config_ls.append((embedding_dim, learning_rate, dropout_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62e58404",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_ls = []\n",
    "test_loss_ls = []\n",
    "full_test_loss_ls = []\n",
    "best_epoch_ls = []\n",
    "best_test_loss_ls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c620dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for config in config_ls:\n",
    "    embedding_dim, learning_rate, dropout_prob = config\n",
    "    model = GNNSAGERecommenderwithSkipConnections(num_users, num_products, user_feature_dim, product_feature_dim, embedding_dim, dropout_prob)\n",
    "    model.to(device=device)\n",
    "    train_loss, test_loss, best_model, best_epoch = train_model(model, train_edge_index, train_edge_weights, test_edge_index, test_edge_weights,\n",
    "                                                    user_nodes, product_nodes, num_epochs = num_epochs, print_progress=False, lr = learning_rate, \n",
    "                                                    give_epoch= True)\n",
    "    \n",
    "    full_test_loss, _ = final_evaluation(model, test_edge_index, test_edge_weights, user_nodes, product_nodes, device, print_test=False)\n",
    "    model.load_state_dict(best_model)\n",
    "    best_test_loss, _ = final_evaluation(model, test_edge_index, test_edge_weights, user_nodes, product_nodes, device, print_test=False)\n",
    "    train_loss_ls.append(train_loss)\n",
    "    test_loss_ls.append(test_loss)\n",
    "    full_test_loss_ls.append(full_test_loss.item())\n",
    "    best_epoch_ls.append(best_epoch)\n",
    "    best_test_loss_ls.append(best_test_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0a08cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = make_df(config_ls, [\"embedding_dim\", \"learning_rate\", \"dropout_prob\"], train_loss_ls, test_loss_ls, full_test_loss_ls, best_epoch_ls, best_test_loss_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f000392",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_parquet(f\"results/{results_folder}/hyper_param_tuning.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
