{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mxAlL1yqVvNr","executionInfo":{"status":"ok","timestamp":1745322952323,"user_tz":-480,"elapsed":25082,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}},"outputId":"7bd3cb21-5ff3-4307-88bd-78d7b2959d4a"},"id":"mxAlL1yqVvNr","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["import os\n","\n","folder_path = '/content/drive/My Drive/dl project self/GNN_recommender_system-vik_dev'\n","os.chdir(folder_path)\n","print(f\"Current working directory: {os.getcwd()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3xmB3J9HVvLq","executionInfo":{"status":"ok","timestamp":1745322954407,"user_tz":-480,"elapsed":2085,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}},"outputId":"211b842f-281b-43fc-a02e-eaa224ad91df"},"id":"3xmB3J9HVvLq","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Current working directory: /content/drive/My Drive/dl project self/GNN_recommender_system-vik_dev\n"]}]},{"cell_type":"code","execution_count":3,"id":"faab79af","metadata":{"id":"faab79af","executionInfo":{"status":"ok","timestamp":1745322954852,"user_tz":-480,"elapsed":445,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","id":"4c135a5c","metadata":{"id":"4c135a5c"},"source":["# Introduction\n","\n","This is a template code with instructions on how to create and use the GNN model.   \n","This notebook skeleton uses train only\n","Straight away use test for the test\n","\n","For code without the instructions, look at `00_06_barebones_train_test.ipynb`  "]},{"cell_type":"markdown","id":"e31bd5b2","metadata":{"id":"e31bd5b2"},"source":["# Imports"]},{"cell_type":"code","source":["!pip install torch_geometric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWNxL8KGV_sc","executionInfo":{"status":"ok","timestamp":1745322959562,"user_tz":-480,"elapsed":4712,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}},"outputId":"1b83a15e-a475-4ef9-e05d-6035034f2d9d"},"id":"rWNxL8KGV_sc","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch_geometric\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.19.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n","Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch_geometric\n","Successfully installed torch_geometric-2.6.1\n"]}]},{"cell_type":"code","execution_count":5,"id":"6962fb86","metadata":{"id":"6962fb86","executionInfo":{"status":"ok","timestamp":1745322981471,"user_tz":-480,"elapsed":21908,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","\n","from utils.setup_nodes import create_edge_lists\n","from utils.graph_helpers import train_model_without_test, plot_train_val_loss, final_evaluation\n","from utils.graph_model import GAT_model, GATv2_model\n","from utils.general import seed_everything\n","from utils.predictions import recommend_products, pretty_print_recomendations, evaluate_recall"]},{"cell_type":"markdown","id":"84f3eb4e","metadata":{"id":"84f3eb4e"},"source":["# Set seed"]},{"cell_type":"code","execution_count":6,"id":"036c6543","metadata":{"id":"036c6543","executionInfo":{"status":"ok","timestamp":1745322982268,"user_tz":-480,"elapsed":807,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["seed_everything()"]},{"cell_type":"markdown","id":"10aad281","metadata":{"id":"10aad281"},"source":["# Set variables\n","\n","1. `user_split` is either `train_test_valid` or `train_test`\n","2. `prod_embed_name` is the name of the embeddings to be used for product\n","3. `user_embed_name` is the name of the embeddings to be used for user (note the files will be preprended with train/test/split)\n","4. `*_dir` is the respective file paths\n","5. `device` cuda or cpu depending on your machine\n","6. `*_cols` the cols to load from the dataframes (change if you need to change the features)\n","7. `fill_users` the method to fill up the new user data (zero or mean)"]},{"cell_type":"code","execution_count":7,"id":"335eaf2c","metadata":{"id":"335eaf2c","executionInfo":{"status":"ok","timestamp":1745322982348,"user_tz":-480,"elapsed":87,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["user_split = \"train_test\"\n","prod_embed_name = \"meta_features_512\"\n","user_embed_name = \"user_reviews_features_512\"\n","\n","data_dir = \"data\"\n","product_dir = \"full_data\"\n","embedding_dir = \"embedding\"\n","\n","device = \"cuda\"\n","\n","product_cols = [\"parent_asin\", \"average_rating\", \"rating_number\"]\n","user_cols = [\"user_id\", \"rating_mean\", \"rating_count\", \"helpful_vote_mean\", \"helpful_vote_gte_1\", \"verified_purchase_mean\", \"last_active_in_days_min\",\n","            \"last_active_in_days_max\", \"word_count_mean\"]\n","edge_cols = [\"user_id\", \"parent_asin\", \"rating\"]\n","\n","fill_users = \"zero\""]},{"cell_type":"markdown","id":"4433f934","metadata":{"id":"4433f934"},"source":["# Load data\n","\n","Take special attention to what is being loaded as a the test set.  \n","Remember if you want test data, set the value of `user_split` to `train_test` in the previous cell\n","\n","Also, I am limiting the number of columns being read in. So edit accordingly to what colum values are needed for the current set up\n","\n","If there is more than 1 tensor for the embedding, sugesstion is to do a torch.cat into a single longer tensor first and then carry it on to the next step. So load under different name then join it back to as product_emebdding, train_user_embedding and test_user_embedding"]},{"cell_type":"code","execution_count":8,"id":"8e78d280","metadata":{"id":"8e78d280","executionInfo":{"status":"ok","timestamp":1745323006085,"user_tz":-480,"elapsed":23739,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["product_df = pd.read_parquet(f\"{data_dir}/{product_dir}/product_df.parquet\", columns = product_cols)\n","train_user_df = pd.read_parquet(f\"{data_dir}/{user_split}_split/train_agg.parquet\", columns = user_cols)\n","train_user_edges = pd.read_parquet(f\"{data_dir}/{user_split}_split/train.parquet\", columns = edge_cols)\n","\n","if user_split == \"train_test_valid\":\n","    test_user_df = pd.read_parquet(f\"{data_dir}/{user_split}_split/valid_agg.parquet\", columns = user_cols)\n","    test_user_edges = pd.read_parquet(f\"{data_dir}/{user_split}_split/valid.parquet\", columns = edge_cols)\n","else:\n","    test_user_df = pd.read_parquet(f\"{data_dir}/{user_split}_split/test_agg.parquet\", columns = user_cols)\n","    test_user_edges = pd.read_parquet(f\"{data_dir}/{user_split}_split/test.parquet\", columns = edge_cols)\n"]},{"cell_type":"code","execution_count":9,"id":"2dc6f785","metadata":{"id":"2dc6f785","executionInfo":{"status":"ok","timestamp":1745323040812,"user_tz":-480,"elapsed":34718,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["product_embedding = torch.load(f\"{data_dir}/{embedding_dir}/product/{prod_embed_name}.pt\")\n","train_user_embedding = torch.load(f\"{data_dir}/{embedding_dir}/{user_split}_split/train_{user_embed_name}.pt\")\n","if user_split == \"train_test_valid\":\n","    test_user_embedding = torch.load(f\"{data_dir}/{embedding_dir}/{user_split}_split/valid_{user_embed_name}.pt\")\n","else:\n","    test_user_embedding = torch.load(f\"{data_dir}/{embedding_dir}/{user_split}_split/test_{user_embed_name}.pt\")"]},{"cell_type":"markdown","id":"f1edaced","metadata":{"id":"f1edaced"},"source":["# Make nodes\n","\n","We need to do a few things\n","1. Make a super user df - so that all the nodes are inside the graph and the idx would be correct later\n","2. Set up an index mapping from ids to idx (note that the product index need to be offeset)\n","3. Concat information to form the product nodes\n","4. Concat information to form the user nodes - only for the train users, test users need to init as something if they dont exist in train (maybe zero or mean)\n","5. Create edge list for train and test (using the idx)\n","\n","For product nodes, we assume the df has information, less the ids. If there is no information, then change the creation accordingly  \n","\n","For the user nodes, for users in test but not in train, the current method is to user zero.  \n","There is also a flag to fill with mean instead"]},{"cell_type":"code","execution_count":10,"id":"51709e28","metadata":{"id":"51709e28","executionInfo":{"status":"ok","timestamp":1745323041404,"user_tz":-480,"elapsed":596,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["# Add the embedding\n","train_user_df[\"embedding\"] = list(train_user_embedding.numpy())\n","test_user_df[\"embedding\"] = list(test_user_embedding.numpy())\n","\n","# Concat user nodes\n","additional_test_users = test_user_df[~test_user_df.user_id.isin(train_user_df.user_id)].copy()\n","\n","## these are users that need to be zero-ed out\n","additional_test_users = test_user_df[~test_user_df.user_id.isin(train_user_df.user_id)].copy()\n","additional_test_users[\"embedding\"] = list(torch.zeros((len(additional_test_users), test_user_embedding.shape[1])).numpy())\n","if fill_users == \"zero\":\n","    additional_test_users.iloc[:, 1:-1] = 0\n","elif fill_users == \"mean\":\n","    additional_test_users.iloc[:, 1:-1] = train_user_df.iloc[:, 1:].mean()\n","\n","# Make super user df\n","user_df = pd.concat([train_user_df, additional_test_users])"]},{"cell_type":"code","execution_count":11,"id":"591e1931","metadata":{"id":"591e1931","executionInfo":{"status":"ok","timestamp":1745323042497,"user_tz":-480,"elapsed":1089,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["# Set up id mapping\n","offset = user_df.user_id.nunique()\n","user_id_to_idx = {unique_id : idx for idx, unique_id in enumerate(user_df.user_id.unique())}\n","prod_id_to_idx = {unique_id : offset + idx for idx, unique_id in enumerate(product_df.parent_asin.unique())}\n","\n","# Add to df\n","product_df[\"prod_idx\"] = product_df.parent_asin.apply(lambda x: prod_id_to_idx[x])\n","train_user_edges[\"user_idx\"] = train_user_edges.user_id.apply(lambda x: user_id_to_idx[x])\n","test_user_edges[\"user_idx\"] = test_user_edges.user_id.apply(lambda x: user_id_to_idx[x])\n","train_user_edges[\"prod_idx\"] = train_user_edges.parent_asin.apply(lambda x: prod_id_to_idx[x])\n","test_user_edges[\"prod_idx\"] = test_user_edges.parent_asin.apply(lambda x: prod_id_to_idx[x])"]},{"cell_type":"code","execution_count":12,"id":"f2105813","metadata":{"id":"f2105813","executionInfo":{"status":"ok","timestamp":1745323043070,"user_tz":-480,"elapsed":579,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["# Concat product nodes\n","product_nodes = torch.cat([torch.tensor(product_df.drop([\"parent_asin\", \"prod_idx\"], axis = 1).to_numpy()), product_embedding], dim = 1)"]},{"cell_type":"code","execution_count":13,"id":"775f57ca","metadata":{"id":"775f57ca","executionInfo":{"status":"ok","timestamp":1745323048314,"user_tz":-480,"elapsed":5241,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["# concat user nodes\n","user_embed = torch.tensor(np.vstack(user_df[\"embedding\"].values))\n","user_info = torch.tensor(user_df.drop([\"user_id\", \"embedding\"], axis = 1).to_numpy())\n","user_nodes = torch.cat([user_info, user_embed], dim = 1)"]},{"cell_type":"code","execution_count":14,"id":"5ccf9384","metadata":{"id":"5ccf9384","executionInfo":{"status":"ok","timestamp":1745323048554,"user_tz":-480,"elapsed":242,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["# Create edge list\n","train_edge_index, train_edge_weights = create_edge_lists(train_user_edges)\n","test_edge_index, test_edge_weights = create_edge_lists(train_user_edges)"]},{"cell_type":"markdown","id":"ea9311e4","metadata":{"id":"ea9311e4"},"source":["# Move to GPU\n","\n","This is placed here for clarity"]},{"cell_type":"code","execution_count":15,"id":"8118624f","metadata":{"id":"8118624f","executionInfo":{"status":"ok","timestamp":1745323050754,"user_tz":-480,"elapsed":2202,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["product_nodes = product_nodes.type(torch.float).to(device)\n","user_nodes = user_nodes.type(torch.float).to(device)\n","train_edge_index = train_edge_index.to(device)\n","train_edge_weights = train_edge_weights.to(device)\n","test_edge_index = test_edge_index.to(device)\n","test_edge_weights = test_edge_weights.to(device)"]},{"cell_type":"markdown","id":"c0f10702","metadata":{"id":"c0f10702"},"source":["# Instantiate the model\n","\n","Whatever the model is decided, create it here  \n","ideally assign it to model so easier for the overall run  \n","\n","The model when instantiating will take in the following variables (based on the default architecture that we are doing)\n","1. number of users - create extra embeddings for each user\n","2. number of products - create extra embedding for each product\n","3. user feature dimensions - size of self created information for users\n","4. product feature dimensions - size of self created information for products\n","5. embedding dim - what size the features reduce to (for default base model, this was the same for every place)\n","\n","If you make any changes, feel free to edit accordingly\n","\n","Finally don't forget to move the model to gpu"]},{"cell_type":"code","execution_count":16,"id":"6576d80a","metadata":{"id":"6576d80a","executionInfo":{"status":"ok","timestamp":1745323050759,"user_tz":-480,"elapsed":7,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["# Set up model features\n","num_users = len(user_df)\n","num_products = len(product_df)\n","user_feature_dim = user_nodes.shape[1]\n","product_feature_dim = product_nodes.shape[1]"]},{"cell_type":"code","execution_count":17,"id":"def696ad","metadata":{"id":"def696ad","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1745323051082,"user_tz":-480,"elapsed":271,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}},"outputId":"d5db1e3c-10a2-4ca3-bdea-f2e90774b1d9"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"GAT_model.__init__() got an unexpected keyword argument 'lr'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-93f6a5fe249e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instantiate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model = GAT_model(num_users, num_products, user_feature_dim, product_feature_dim,\n\u001b[0m\u001b[1;32m      3\u001b[0m                   \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mdropout_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   lr=0.01)\n","\u001b[0;31mTypeError\u001b[0m: GAT_model.__init__() got an unexpected keyword argument 'lr'"]}],"source":["# Instantiate the model\n","model = GAT_model(num_users, num_products, user_feature_dim, product_feature_dim,\n","                  hidden_dim=64,\n","                  dropout_prob=0.1,\n","                  lr=0.01)"]},{"cell_type":"code","execution_count":null,"id":"5010171b","metadata":{"id":"5010171b","executionInfo":{"status":"aborted","timestamp":1745323051118,"user_tz":-480,"elapsed":20,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["# move the model\n","model.to(device)"]},{"cell_type":"markdown","id":"5f43ded2","metadata":{"id":"5f43ded2"},"source":["# Train the model\n","\n","Pass the model, data and all into a loop and let it train"]},{"cell_type":"code","execution_count":null,"id":"1c888e6c","metadata":{"id":"1c888e6c","executionInfo":{"status":"aborted","timestamp":1745323051121,"user_tz":-480,"elapsed":10,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["train_loss, test_loss, best_model = train_model(GAT_model, train_edge_index, train_edge_weights, test_edge_index, test_edge_weights,\n","                                                 user_nodes, product_nodes, num_epochs = 2000, print_progress=True, print_freq=10)"]},{"cell_type":"code","execution_count":null,"id":"e8886b3d","metadata":{"id":"e8886b3d","executionInfo":{"status":"aborted","timestamp":1745323051124,"user_tz":-480,"elapsed":11,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["plot_train_val_loss(train_losses)"]},{"cell_type":"markdown","id":"0ac6a6a0","metadata":{"id":"0ac6a6a0"},"source":["# Final model performance\n","\n","This is simply to load the best model during training and to print that loss  \n","Has no other purpose"]},{"cell_type":"code","execution_count":null,"id":"6c440476","metadata":{"id":"6c440476","executionInfo":{"status":"aborted","timestamp":1745323051126,"user_tz":-480,"elapsed":12,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["final_evaluation(model, test_edge_index, test_edge_weights, user_nodes, product_nodes, device)"]},{"cell_type":"markdown","id":"14a3e6d0","metadata":{"id":"14a3e6d0"},"source":["# Metrics\n","\n","We have two kinds\n","1. Recall at 10\n","2. NDCG at 10\n","\n","The recall takes about ___ mins and will generally be bad   \n","NDCG is a work in progress so TBC"]},{"cell_type":"code","execution_count":null,"id":"3e1e88d8","metadata":{"id":"3e1e88d8","executionInfo":{"status":"aborted","timestamp":1745323051153,"user_tz":-480,"elapsed":5,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["product_idx_tensor = torch.tensor(list(prod_id_to_idx.values()), dtype=torch.long, device = device)\n","test_edges_grp = test_user_edges.groupby(\"user_idx\").prod_idx.apply(list).reset_index()\n","test_edges_users = test_edges_grp.user_idx.to_list()"]},{"cell_type":"code","execution_count":null,"id":"77bfdc22","metadata":{"id":"77bfdc22","executionInfo":{"status":"aborted","timestamp":1745323051154,"user_tz":-480,"elapsed":5,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["predictions = get_top_k_preds(model, test_edges_users, 10, 32, user_nodes, product_nodes, product_idx_tensor, device) # about 5 min to run\n","test_edges_grp[\"prediction\"] = list(torch.vstack(predictions).cpu().numpy())\n","test_edges_grp[\"match_count\"] = test_edges_grp.apply(lambda x: len(set(x.prod_idx).intersection(set(x.prediction))), axis = 1)"]},{"cell_type":"code","execution_count":null,"id":"75e7e57a","metadata":{"id":"75e7e57a","executionInfo":{"status":"aborted","timestamp":1745323051155,"user_tz":-480,"elapsed":5,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["# Overall recall\n","(test_edges_grp[\"match_count\"] / test_edges_grp.prod_idx.apply(len)).mean()"]},{"cell_type":"code","execution_count":null,"id":"269b56f3","metadata":{"id":"269b56f3","executionInfo":{"status":"aborted","timestamp":1745323051157,"user_tz":-480,"elapsed":6,"user":{"displayName":"Shaun Tan","userId":"17552663312636960341"}}},"outputs":[],"source":["# Only those with prior history\n","existing_test_edges_grp = test_edges_grp[test_edges_grp.user_idx.isin(train_user_df.user_id.apply(lambda x: user_id_to_idx[x]))]\n","(existing_test_edges_grp[\"match_count\"] / existing_test_edges_grp.prod_idx.apply(len)).mean()"]},{"cell_type":"markdown","id":"5452c781","metadata":{"id":"5452c781"},"source":["# Show recomendations\n","\n","This is just to sample and see what kind of results we get   \n","I am going to do three kinds of sampling\n","1. Pure random of the test set\n","2. Select test set that have some existance in the training set\n","3. Take the test set that dont have existance in the training set but use their user node information\n","\n","\n","But first we need to create a reverse mapping that does the offset\n","Also need to load up a df to map ids to titles"]},{"cell_type":"code","execution_count":null,"id":"30ceeb8b","metadata":{"id":"30ceeb8b"},"outputs":[],"source":["title_mapping = pd.read_parquet(f\"{data_dir}/{product_dir}/product_df.parquet\", columns = [\"parent_asin\", \"title\"])\n","prod_idx_to_id = {idx - offset: asin for asin, idx in prod_id_to_idx.items()}"]},{"cell_type":"code","execution_count":null,"id":"d4361e15","metadata":{"id":"d4361e15","outputId":"553e0c09-c7ed-4008-eecd-e53fd29abc43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Product 1: 2 Pieces Pearls Headband Wide Headband Velvet Vintage Twisted Headwear for Girl Woman Hair Accessories (Wine Red, Pink)\n","Product 2: Beauty Concepts 4 Pack Lip Balm Set- Moisturizing Lip Balm, Lip Repair and Hydration, in Honey, Mango, Berry, and Sweet Lemon, with Pink Floral Gift Box\n","Product 3: Nidoul 6 PCS Tie Dye Elastic Headbands for Girls, Unicorn Mermaid Non Slip Hair Bands, Adjustable Hair Accessories for Teens, Girls' Cute Birthday Party Favors Gifts\n","Product 4: 6PCS Knotted Headband for Women,AOPRIE Twist Knot Turban Headband Yoga Hair Band Fashion Elastic Hair Accessories for Women and Girls,Children 6 Colors\n","Product 5: 4 Pieces Big Hair Claw Clips Colorful Nonslip Large Claw Clip for Women and Girls Thin Hair, Strong Hold Hair Clips Hair Grip Clamps Styling Accessories for Women Girls\n","Product 6: 5 Inches Hair Bows Clips for Girls, Hair Bows Alligator Clips for Girl Grosgrain Ribbon Hair Barrettes Accessories for Toddler Kids Girls …\n","Product 7: TOBATOBA 6 Pack Wide Headbands Knot Velvet Hairband Vintage Head Wrap Elastic Hair Hoops Fashion Hair Accessories for Women, Christmas Party Decorations,Include 3 leapord Headbands and 3 Slid Color\n","Product 8: Body Prescriptions Set of Four Face Masks, Moisturizing Face Mask Variety Pack, Revitalizing Collection of Grapefruit, Coconut, Pineapple and Berry Infused Facial Masks for Women's Skincare\n","Product 9: AOPRIE 4 Pcs Knot Headbands Leopard Headbands for Women Turban Headband Pearl Headbands for Women Cheetah Headbands for Women Turban Headbands for Women Diademas para Mujer\n","Product 10: Sidaila Long Curly Wigs Synthetic Glueless Natural Wavy Wig for Women, Shoulder Length Bob Synthetic Cosplay Wig 16 Inch Heat Resistant Hair Wig With Bangs for Girl Costume Wigs (Green)\n"]}],"source":["# The pure random\n","user_id = test_user_df.user_id.sample(1).item()\n","recommended_products, predictions = recommend_products(model, user_id, user_id_to_idx, prod_id_to_idx, user_nodes, product_nodes,\n","                                                       prod_idx_to_id, top_k=10, device = device)\n","pretty_print_recomendations(recommended_products, title_mapping, \"title\")"]},{"cell_type":"code","execution_count":null,"id":"37722027","metadata":{"id":"37722027"},"outputs":[],"source":["# The user with some data\n","existing_test_users = test_user_df[test_user_df.user_id.isin(train_user_df.user_id)].copy()[[\"user_id\"]]"]},{"cell_type":"code","execution_count":null,"id":"bda083de","metadata":{"id":"bda083de","outputId":"17508147-4ea2-4dff-b952-8875e6d7c608"},"outputs":[{"name":"stdout","output_type":"stream","text":["Product 1: 2 Pieces Pearls Headband Wide Headband Velvet Vintage Twisted Headwear for Girl Woman Hair Accessories (Wine Red, Pink)\n","Product 2: AOPRIE 4 Pcs Knot Headbands Leopard Headbands for Women Turban Headband Pearl Headbands for Women Cheetah Headbands for Women Turban Headbands for Women Diademas para Mujer\n","Product 3: LZYMSZ 12PCS Floral Print Headwrap,Bobo Headbands with Vintage Printed,Criss Cross Knotted Hair Band Yoga Head Wraps Sports Elastic Twist Turban for Women Girls (color-3)\n","Product 4: 4 Pieces Big Hair Claw Clips Colorful Nonslip Large Claw Clip for Women and Girls Thin Hair, Strong Hold Hair Clips Hair Grip Clamps Styling Accessories for Women Girls\n","Product 5: Jeairts Boho Bandeau Headbands Wide Running Hair Bands Knot Thick Turban Head Wraps Elastic Fabric Hair Scarfs Stylish Hair Accessories for Women and Girls(Pack of 3)\n","Product 6: Nidoul 6 PCS Tie Dye Elastic Headbands for Girls, Unicorn Mermaid Non Slip Hair Bands, Adjustable Hair Accessories for Teens, Girls' Cute Birthday Party Favors Gifts\n","Product 7: 5 Inches Hair Bows Clips for Girls, Hair Bows Alligator Clips for Girl Grosgrain Ribbon Hair Barrettes Accessories for Toddler Kids Girls …\n","Product 8: TOBATOBA 6 Pack Wide Headbands Knot Velvet Hairband Vintage Head Wrap Elastic Hair Hoops Fashion Hair Accessories for Women, Christmas Party Decorations,Include 3 leapord Headbands and 3 Slid Color\n","Product 9: 6PCS Knotted Headband for Women,AOPRIE Twist Knot Turban Headband Yoga Hair Band Fashion Elastic Hair Accessories for Women and Girls,Children 6 Colors\n","Product 10: 10 Packs Bunny Ear Scrunchies, Taomoder Soft Silk Leopard Scrunchies Hair Bows Satin Hair Scrunchies for Women Cute Scrunchies for Hair Ponytail Holder Hair Ties Elastic Hair Bands\n"]}],"source":["user_id = existing_test_users.user_id.sample(1).item()\n","recommended_products, predictions = recommend_products(model, user_id, user_id_to_idx, prod_id_to_idx, user_nodes, product_nodes,\n","                                                       prod_idx_to_id, top_k=10, device = device)\n","pretty_print_recomendations(recommended_products, title_mapping, \"title\")"]},{"cell_type":"code","execution_count":null,"id":"38f718d9","metadata":{"id":"38f718d9"},"outputs":[],"source":["# The boosted way\n","# This is just to see if existing data (a bit of data leak) can help improve performance\n","boosted_additional_test_users = test_user_df[~test_user_df.user_id.isin(train_user_df.user_id)].copy()\n","boosted_user_df = pd.concat([train_user_df, boosted_additional_test_users])\n","boosted_user_embed = torch.tensor(np.vstack(boosted_user_df[\"embedding\"].values))\n","boosted_user_info = torch.tensor(boosted_user_df.drop([\"user_id\", \"embedding\"], axis = 1).to_numpy())\n","boosted_user_nodes = torch.cat([boosted_user_embed, boosted_user_info], dim = 1)"]},{"cell_type":"code","execution_count":null,"id":"2ba63127","metadata":{"id":"2ba63127","outputId":"bb5914dc-cd1b-4871-85e6-7ccba5dd005d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Product 1: 2 Pieces Pearls Headband Wide Headband Velvet Vintage Twisted Headwear for Girl Woman Hair Accessories (Wine Red, Pink)\n","Product 2: LZYMSZ 12PCS Floral Print Headwrap,Bobo Headbands with Vintage Printed,Criss Cross Knotted Hair Band Yoga Head Wraps Sports Elastic Twist Turban for Women Girls (color-3)\n","Product 3: 4 Pieces Big Hair Claw Clips Colorful Nonslip Large Claw Clip for Women and Girls Thin Hair, Strong Hold Hair Clips Hair Grip Clamps Styling Accessories for Women Girls\n","Product 4: AOPRIE 4 Pcs Knot Headbands Leopard Headbands for Women Turban Headband Pearl Headbands for Women Cheetah Headbands for Women Turban Headbands for Women Diademas para Mujer\n","Product 5: Nidoul 6 PCS Tie Dye Elastic Headbands for Girls, Unicorn Mermaid Non Slip Hair Bands, Adjustable Hair Accessories for Teens, Girls' Cute Birthday Party Favors Gifts\n","Product 6: 6PCS Knotted Headband for Women,AOPRIE Twist Knot Turban Headband Yoga Hair Band Fashion Elastic Hair Accessories for Women and Girls,Children 6 Colors\n","Product 7: Hvinie Knotted Leopard Wide Headbands for Women 4 Pack, Fashion Elegant Vintage Elastic Cross Knot Hairband Headwrap for Women Girls Hair Accessories\n","Product 8: 12 Pieces Teeth Headband Plastic Velvet Hair Scrunchies Set, Include Plastic Comb Hairband Hair Bands Scrunchies and Hair Hoop Hairband with Non Slip Teeth for Women Girls Outdoor Sports Yoga\n","Product 9: 5 Inches Hair Bows Clips for Girls, Hair Bows Alligator Clips for Girl Grosgrain Ribbon Hair Barrettes Accessories for Toddler Kids Girls …\n","Product 10: Jeairts Boho Bandeau Headbands Wide Running Hair Bands Knot Thick Turban Head Wraps Elastic Fabric Hair Scarfs Stylish Hair Accessories for Women and Girls(Pack of 3)\n"]}],"source":["user_id = boosted_user_df.user_id.sample(1).item()\n","recommended_products, predictions = recommend_products(model, user_id, user_id_to_idx, prod_id_to_idx, user_nodes, product_nodes,\n","                                                       prod_idx_to_id, top_k=10, device = device)\n","pretty_print_recomendations(recommended_products, title_mapping, \"title\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.9"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}