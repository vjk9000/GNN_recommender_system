{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "This notebook is to make a fixed test set for all future modelling   \n",
    "This is an improvement compared to the original to allow for more flexibility of the dataset creeations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viknesh/.venv_ls/dl_proj/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct from the source \n",
    "reviews_dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_All_Beauty\", trust_remote_code=True)\n",
    "product_dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_All_Beauty\", split=\"full\", trust_remote_code=True)\n",
    "\n",
    "review_df = reviews_dataset['full'].to_pandas()\n",
    "product_df = product_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned data\n",
    "agg_user_df = pd.read_csv(\"data/cleaned/user_metadata.csv\")\n",
    "new_product_df = pd.read_csv(\"data/cleaned/product_metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tally the ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_parent_asin = (set(review_df.parent_asin)\n",
    "                      .intersection(set(product_df.parent_asin))\n",
    "                      .intersection(set(new_product_df.parent_asin))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = review_df[review_df.parent_asin.isin(useful_parent_asin)]\n",
    "product_df = product_df[product_df.parent_asin.isin(useful_parent_asin)]\n",
    "new_product_df = new_product_df[new_product_df.parent_asin.isin(useful_parent_asin)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_user_id = (set(review_df.user_id).intersection(set(agg_user_df.user_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = review_df[review_df.user_id.isin(useful_user_id)]\n",
    "agg_user_df = agg_user_df[agg_user_df.user_id.isin(useful_user_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove same reviews \n",
    "\n",
    "This is for when the user has more than 1 rating for the same product \n",
    "There are a few ways to remove and this is not the only way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two possible options (about 2%)\n",
    "# .groupby([\"user_id\", \"parent_asin\"]).mean().reset_index()\n",
    "# .drop_duplicates(subset = [\"user_id\", \"parent_asin\"]).sort_values([\"user_id\", \"timestamp\"]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9891005772412371"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_df.drop_duplicates(subset = [\"user_id\", \"parent_asin\"]).reset_index(drop = True)) / len(review_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = review_df.drop_duplicates(subset = [\"user_id\", \"parent_asin\"]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the full data\n",
    "\n",
    "1. df for the user features (numeric) - x2, aggregated and not \n",
    "2. df for the user features (string data) - x2, aggregated and not \n",
    "3. df for the product features (numeric)\n",
    "4. df for the product features (string)\n",
    "5. df for the edges of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_numeric_agg = agg_user_df.drop(\"reviews\", axis = 1)\n",
    "user_features_numeric_pre_agg = review_df[[\"user_id\", \"parent_asin\", \"rating\", \"helpful_vote\", \"verified_purchase\"]]\n",
    "user_features_string_agg = agg_user_df[[\"user_id\", \"reviews\"]]\n",
    "user_features_string_pre_agg = review_df[[\"user_id\", \"parent_asin\", \"title\", \"text\", ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_features_numeric = product_df[[\"parent_asin\", \"main_category\", \"average_rating\", \"rating_number\", \"price\"]]\n",
    "product_features_string = pd.merge(product_df[[\"parent_asin\", \"title\", \"features\", \"description\", \"store\", \"details\"]], new_product_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df = review_df[[\"user_id\", \"parent_asin\", \"rating\", \"timestamp\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping dict \n",
    "\n",
    "This is for the full graph   \n",
    "We assume no new products / users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_to_idx = {unique_id : idx for idx, unique_id in enumerate(edge_df.user_id.unique())}\n",
    "prod_id_to_idx = {unique_id : idx for idx, unique_id in enumerate(edge_df.parent_asin.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df[\"user_idx\"] = edge_df.user_id.apply(lambda x: user_id_to_idx[x])\n",
    "edge_df[\"prod_idx\"] = edge_df.parent_asin.apply(lambda x: prod_id_to_idx[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train test val \n",
    "\n",
    "This is only applicable to the edges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mark = np.quantile(edge_df.timestamp, 0.7)\n",
    "test_mark = np.quantile(edge_df.timestamp, 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edges = edge_df[edge_df.timestamp <= train_mark].copy()\n",
    "test_edges = edge_df[edge_df.timestamp >= test_mark].copy()\n",
    "val_edges = edge_df[(edge_df.timestamp > train_mark) & (edge_df.timestamp < test_mark)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save files \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_numeric_agg.to_parquet(\"data/cleaned_v2/user_features_numeric_agg.parquet\")\n",
    "user_features_numeric_pre_agg.to_parquet(\"data/cleaned_v2/user_features_numeric_pre_agg.parquet\")\n",
    "user_features_string_agg.to_parquet(\"data/cleaned_v2/user_features_string_agg.parquet\")\n",
    "user_features_string_pre_agg.to_parquet(\"data/cleaned_v2/user_features_string_pre_agg.parquet\")\n",
    "product_features_numeric.to_parquet(\"data/cleaned_v2/product_features_numeric.parquet\")\n",
    "product_features_string.to_parquet(\"data/cleaned_v2/product_features_string.parquet\")\n",
    "train_edges.to_parquet(\"data/cleaned_v2/train_edges.parquet\")\n",
    "test_edges.to_parquet(\"data/cleaned_v2/test_edges.parquet\")\n",
    "val_edges.to_parquet(\"data/cleaned_v2/val_edges.parquet\")\n",
    "\n",
    "pickle.dump(user_id_to_idx, open(\"data/cleaned_v2/user_id_to_idx.pkl\", \"wb\"))\n",
    "pickle.dump(prod_id_to_idx, open(\"data/cleaned_v2/prod_id_to_idx.pkl\", \"wb\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
